# ARF-005: Create main apply_review_feedback() function

## User Stories

**As a** developer implementing review feedback workflows
**I want** a single function that orchestrates the entire review feedback application
**So that** both create_epic.py and create_tickets.py can apply review feedback with one function call

**As a** system maintainer
**I want** comprehensive error handling and logging throughout the workflow
**So that** failures are caught, logged, and reported clearly to users

## Acceptance Criteria

1. Function `apply_review_feedback()` exists in cli/utils/review_feedback.py as a public function
2. Function signature matches exactly:
   ```python
   def apply_review_feedback(
       review_artifact_path: Path,
       builder_session_id: str,
       context: ClaudeContext,
       targets: ReviewTargets,
       console: Console
   ) -> None
   ```
3. Function implements all 6 workflow steps in order:
   - Step 1: Read review artifact from review_artifact_path
   - Step 2: Build feedback application prompt using _build_feedback_prompt()
   - Step 3: Create template documentation using _create_template_doc()
   - Step 4: Resume builder session with feedback prompt using ClaudeRunner
   - Step 5: Validate documentation was completed (check frontmatter status)
   - Step 6: Create fallback documentation if needed using _create_fallback_updates_doc()
4. Error handling covers all critical scenarios:
   - Catch FileNotFoundError when review_artifact_path doesn't exist → log and re-raise
   - Catch yaml.YAMLError when parsing frontmatter fails → log and re-raise
   - Catch ClaudeRunnerError when Claude session fails → log, create fallback, continue
   - Catch OSError when file operations fail → log and re-raise
   - Partial failures (some files updated, others not) → log warnings, continue gracefully
5. All errors are logged to `targets.artifacts_dir / targets.error_file_name`
6. Claude stdout/stderr are logged to `targets.artifacts_dir / targets.log_file_name`
7. Console output requirements met:
   - Display progress message "Applying review feedback..." at start
   - Show spinner or progress indicator during Claude execution
   - Display success message with file change count when complete
   - Display path to documentation artifact when complete
   - Show error messages clearly when failures occur
   - Use rich Console for formatted output (tables, colors, etc.)
8. Frontmatter validation logic:
   - Parse YAML frontmatter from template doc after Claude runs
   - Check if status field equals "completed"
   - If status is "in_progress" or missing → Claude failed, create fallback
   - If status is "completed" or "completed_with_errors" → Claude succeeded
9. Function has comprehensive docstring explaining:
   - Purpose: Orchestrate review feedback application workflow
   - Parameters: review_artifact_path, builder_session_id, context, targets, console
   - Side effects: Edits files, creates logs, creates documentation
   - Error handling: What exceptions are caught and how
   - Return value: None (side effects only)
10. Type hints present on all parameters and return value
11. ClaudeRunner is used correctly for session resumption:
    - Import from appropriate module
    - Call with correct parameters (context, prompt, builder_session_id)
    - Capture stdout and stderr for logging
12. Function integrates with existing buildspec infrastructure:
    - Uses Path from pathlib consistently
    - Uses Console from rich for output
    - Uses ClaudeContext for session management
    - Follows project error handling patterns

## Technical Context

This is the main orchestration function that ties together all the helper functions from ARF-001 through ARF-004. It implements the complete workflow for applying review feedback from a review artifact to target files.

**Workflow Details:**

**Step 1: Read review artifact**
The review artifact is a YAML file created by epic-file-review or epic-review commands. It contains:
```yaml
---
status: completed
review_type: epic-file  # or "epic"
---

# Review Content
[Structured review feedback with priority levels]
```

Parse this file, extract the review content, and verify status is "completed".

**Step 2: Build prompt**
Call _build_feedback_prompt() with:
- review_content: The body of the review artifact (everything after frontmatter)
- targets: The ReviewTargets configuration
- builder_session_id: Session ID for traceability

**Step 3: Create template**
Call _create_template_doc() to write the initial template with status=in_progress. This must happen BEFORE invoking Claude so the template exists when Claude runs.

**Step 4: Resume session**
Use ClaudeRunner to resume the builder session with the feedback prompt. ClaudeRunner will:
- Load the session context
- Send the prompt to Claude
- Execute Claude's tool calls (file edits)
- Capture stdout and stderr

**Step 5: Validate completion**
After Claude finishes, read the template doc and parse its frontmatter:
```python
template_path = targets.artifacts_dir / targets.updates_doc_name
with open(template_path, 'r') as f:
    content = f.read()
    # Parse YAML frontmatter between --- markers
    if content.startswith('---'):
        parts = content.split('---', 2)
        if len(parts) >= 3:
            frontmatter = yaml.safe_load(parts[1])
            status = frontmatter.get('status', 'in_progress')
```

If status is "completed" or "completed_with_errors", Claude succeeded. Otherwise, create fallback.

**Step 6: Create fallback if needed**
If validation fails (status still in_progress), call _create_fallback_updates_doc() with stdout and stderr from the Claude session.

**Error Handling Strategy:**

- **FileNotFoundError (review artifact)**: Log "Review artifact not found: {path}", re-raise. This is fatal - can't proceed without review.
- **yaml.YAMLError**: Log "Failed to parse review artifact YAML", re-raise. Malformed input is fatal.
- **ClaudeRunnerError**: Log "Claude failed during review feedback", create fallback doc, DON'T re-raise. Partial success is acceptable.
- **OSError (file operations)**: Log "File operation failed: {error}", re-raise. Disk errors are fatal.
- **Partial failures**: If epic YAML updates but some tickets don't, log warnings but continue. The fallback doc will capture details.

**Console Output Examples:**

Success:
```
⠋ Applying review feedback...
✓ Review feedback applied successfully
  • Epic YAML updated
  • 5 ticket files updated
  • Documentation: .epics/my-epic/artifacts/epic-review-updates.md
```

Failure:
```
⠋ Applying review feedback...
✗ Claude failed to complete review feedback
  • Created fallback documentation
  • Documentation: .epics/my-epic/artifacts/epic-review-updates.md
  • Check error log: .epics/my-epic/artifacts/epic-review.error.log
```

## Dependencies

**Depends on:**
- ARF-001: Create review_feedback.py utility module with ReviewTargets dataclass
- ARF-002: Extract _build_feedback_prompt() helper function
- ARF-003: Extract _create_template_doc() helper function
- ARF-004: Extract _create_fallback_updates_doc() helper function

**Blocks:**
- ARF-006: Update cli/utils/__init__.py exports
- ARF-007: Refactor create_epic.py to use shared utility
- ARF-008: Integrate review feedback into create_tickets.py

## Collaborative Code Context

**Provides to:**
- ARF-007: create_epic.py will call this function instead of its local implementation
- ARF-008: create_tickets.py will call this function for epic-review feedback application

**Consumes from:**
- ARF-001: ReviewTargets dataclass for configuration
- ARF-002: _build_feedback_prompt() for prompt generation
- ARF-003: _create_template_doc() for template creation
- ARF-004: _create_fallback_updates_doc() for failure recovery

**Integrates with:**
- ClaudeRunner: For executing review feedback with Claude
- ClaudeContext: For session management
- rich.Console: For user-facing output
- pathlib.Path: For file operations
- yaml: For parsing frontmatter

## Function Profiles

### `apply_review_feedback(review_artifact_path: Path, builder_session_id: str, context: ClaudeContext, targets: ReviewTargets, console: Console) -> None`
Main orchestration function for applying review feedback. Reads review artifact, builds prompt, creates template, resumes Claude session, validates completion, and creates fallback if needed. Handles errors gracefully with logging. Provides user feedback via console. Side effects: edits files, creates logs and documentation. Raises FileNotFoundError, yaml.YAMLError, OSError on fatal errors. Catches ClaudeRunnerError and creates fallback instead of failing.

## Automated Tests

### Unit Tests

- `test_apply_review_feedback_success_epic_file()` - Verify successful workflow for epic-file review with mocked ClaudeRunner
- `test_apply_review_feedback_success_epic()` - Verify successful workflow for epic review with mocked ClaudeRunner
- `test_apply_review_feedback_missing_review_artifact()` - Verify FileNotFoundError raised when artifact doesn't exist
- `test_apply_review_feedback_malformed_yaml()` - Verify yaml.YAMLError raised when artifact has invalid YAML
- `test_apply_review_feedback_claude_failure_creates_fallback()` - Verify fallback doc created when Claude fails
- `test_apply_review_feedback_template_not_updated_creates_fallback()` - Verify fallback created when template status remains in_progress
- `test_apply_review_feedback_logs_stdout_stderr()` - Verify Claude stdout/stderr logged to targets.log_file_name
- `test_apply_review_feedback_logs_errors()` - Verify errors logged to targets.error_file_name
- `test_apply_review_feedback_console_output_success()` - Verify console shows success message with file counts
- `test_apply_review_feedback_console_output_failure()` - Verify console shows failure message with paths
- `test_apply_review_feedback_calls_helper_functions()` - Verify all 3 helper functions called in correct order
- `test_apply_review_feedback_builds_prompt_with_correct_params()` - Verify _build_feedback_prompt called with review_content, targets, builder_session_id
- `test_apply_review_feedback_creates_template_before_claude()` - Verify template created before ClaudeRunner invoked
- `test_apply_review_feedback_validates_frontmatter_status()` - Verify frontmatter parsing and status checking logic
- `test_apply_review_feedback_handles_partial_failures()` - Verify partial success (some files updated) logged appropriately
- `test_apply_review_feedback_handles_file_permission_errors()` - Verify OSError caught and logged when files not writable
- `test_apply_review_feedback_empty_review_content()` - Verify function handles review artifact with empty body
- `test_apply_review_feedback_long_review_content()` - Verify function handles very long review content (100000+ chars)

### Integration Tests

- `test_apply_review_feedback_end_to_end_with_real_files()` - Create real review artifact and temp directories, run full workflow, verify files created
- `test_apply_review_feedback_with_mock_claude_runner()` - Use pytest-mock to mock ClaudeRunner, verify integration with rest of system
- `test_apply_review_feedback_matches_create_epic_behavior()` - Verify behavior matches current create_epic.py implementation exactly

### Coverage Target
100% coverage for this function (critical orchestration logic)

**Test Framework**: pytest with pytest-mock

**Test Commands**:
```bash
uv run pytest tests/unit/utils/test_review_feedback.py::TestApplyReviewFeedback -v
uv run pytest tests/unit/utils/test_review_feedback.py -v --cov=cli.utils.review_feedback --cov-report=term-missing
```

## Definition of Done

- [ ] All acceptance criteria met
- [ ] apply_review_feedback() function implemented in cli/utils/review_feedback.py
- [ ] Function signature matches specification exactly
- [ ] All 6 workflow steps implemented in correct order
- [ ] Comprehensive error handling for all scenarios
- [ ] Logging to error and log files working correctly
- [ ] Console output provides clear feedback to users
- [ ] Frontmatter validation logic implemented correctly
- [ ] ClaudeRunner integration working correctly
- [ ] Comprehensive docstring present
- [ ] Type hints on all parameters and return value
- [ ] All tests passing (21 unit + integration tests)
- [ ] Code coverage is 100%
- [ ] Code reviewed
- [ ] No linting errors from ruff

## Non-Goals

- Retrying failed review feedback (single attempt per epic non-goals)
- Validating review artifact structure beyond YAML parsing (assumed correct per epic)
- Preserving backup copies of files before editing (not required per epic non-goals)
- Concurrent review feedback application (single-threaded per epic non-goals)
- Adding metrics or telemetry (out of scope)
- Supporting review types beyond "epic-file" and "epic" (future extension)
- Implementing rollback on failure (manual intervention required)
- Sending notifications about completion/failure (console output only)
- Creating diff/patch files of changes made (Claude's edits are direct)
- Validating that changes match review feedback exactly (trust Claude's judgment)
